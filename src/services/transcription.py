import asyncio
import shutil
import os
import uuid
import time
import logging
import tempfile
from dataclasses import dataclass
from typing import Dict, Any
from fastapi import UploadFile
from starlette.concurrency import run_in_threadpool

# å¼•å…¥æŠ½è±¡æ¥å£å’Œé€‚é…å™¨
from src.core.base_engine import ASREngine
from src.adapters.text import clean_sensevoice_tags

# å®šä¹‰ä¸€ä¸ªç®€å•çš„ä»»åŠ¡å¯¹è±¡ï¼Œç”¨äºåœ¨é˜Ÿåˆ—ä¸­ä¼ é€’
@dataclass
class TranscriptionJob:
    uid: str
    temp_dir: str  # ä»»åŠ¡ä¸“å±ä¸´æ—¶ç›®å½•
    temp_file_path: str # åŸå§‹æ–‡ä»¶è·¯å¾„
    params: Dict[str, Any]
    future: asyncio.Future
    received_at: float

class TranscriptionService:
    """
    è½¬å½•æœåŠ¡è°ƒåº¦å™¨ã€‚
    èŒè´£ï¼š
    1. ç®¡ç†å¼‚æ­¥é˜Ÿåˆ— (Async Queue)
    2. åè°ƒ Engine è¿›è¡Œä¸²è¡Œæ¨ç†
    3. ç®¡ç†ä¸´æ—¶æ–‡ä»¶çš„ç”Ÿå‘½å‘¨æœŸ
    """

    def __init__(self, engine: ASREngine, max_queue_size: int = 50):
        self.engine = engine
        self.logger = logging.getLogger(__name__)
        # æ ¸å¿ƒè®¾è®¡ï¼šä½¿ç”¨ asyncio.Queue å®ç°èƒŒå‹ (Backpressure)
        # å¦‚æœé˜Ÿåˆ—æ»¡ 50 ä¸ªï¼Œå‰ç«¯ä¼šç›´æ¥æ”¶åˆ° 503 é”™è¯¯ï¼Œä¿æŠ¤ç³»ç»Ÿä¸å´©æºƒ
        self.queue = asyncio.Queue(maxsize=max_queue_size)
        self.is_running = False
        self.logger.info(f"ğŸš¦ Service initialized. Queue size: {max_queue_size}")

    async def start_worker(self):
        """å¯åŠ¨åå°æ¶ˆè´¹è€…å¾ªç¯ (åœ¨ main.py çš„ lifespan ä¸­è°ƒç”¨)"""
        self.is_running = True
        asyncio.create_task(self._consume_loop())
        self.logger.info("ğŸ‘· Background worker started.")

    async def submit(self, file: UploadFile, params: Dict[str, Any]) -> Dict[str, Any]:
        """
        æäº¤ä»»åŠ¡æ¥å£ (ä¾› API å±‚è°ƒç”¨)ã€‚
        è¿™ä¸ªæ–¹æ³•æ˜¯éé˜»å¡çš„ï¼šå®ƒåªæ˜¯æŠŠä»»åŠ¡æ‰”è¿›é˜Ÿåˆ—ï¼Œç„¶åç­‰å¾…ç»“æœã€‚
        """
        # 1. æ£€æŸ¥é˜Ÿåˆ—æ˜¯å¦å·²æ»¡ (å¿«é€Ÿå¤±è´¥)
        if self.queue.full():
            raise RuntimeError("Service busy: Queue is full.")

        # 2. "ä¸´æ—¶æ–‡ä»¶ä¹‹èˆ" (The Temp File Dance)
        # ä¸ºæ¯ä¸ªè¯·æ±‚åˆ›å»ºä¸€ä¸ªç‹¬ç«‹çš„ä¸´æ—¶ç›®å½•ï¼Œæ–¹ä¾¿ç»Ÿä¸€æ¸…ç†
        temp_dir = tempfile.mkdtemp(prefix="asr_task_")
        
        try:
            file_ext = os.path.splitext(file.filename)[1] or ".wav"
            # æ–‡ä»¶åä½¿ç”¨ original ä»¥ä¾¿åŒºåˆ†ï¼Œä½†å®é™…ä¸Šåªè¦åœ¨ç›®å½•ä¸‹å°±è¡Œ
            temp_filename = f"original{file_ext}"
            temp_path = os.path.join(temp_dir, temp_filename)

            # å°†ä¸Šä¼ çš„æ–‡ä»¶æµå†™å…¥ç£ç›˜
            with open(temp_path, "wb") as buffer:
                shutil.copyfileobj(file.file, buffer)

            # 3. åˆ›å»ºä»»åŠ¡å¯¹è±¡
            loop = asyncio.get_running_loop()
            future = loop.create_future()
            
            job = TranscriptionJob(
                uid=uuid.uuid4().hex[:8],
                temp_dir=temp_dir,
                temp_file_path=temp_path,
                params=params,
                future=future,
                received_at=time.time()
            )

            # 4. å…¥é˜Ÿ
            await self.queue.put(job)
            
            # 5. ç­‰å¾…å¤„ç†ç»“æœ (Await the future)
            # è¿™é‡Œçš„ await ä¼šæŒ‚èµ·å½“å‰è¯·æ±‚ï¼Œç›´åˆ°åå° worker å®Œæˆå¤„ç†
            result = await future
            return result

        except Exception as e:
            # å¦‚æœåœ¨å…¥é˜Ÿå‰å°±å¤±è´¥äº†ï¼Œç¡®ä¿æ¸…ç†ä¸´æ—¶ç›®å½•
            if os.path.exists(temp_dir):
                shutil.rmtree(temp_dir, ignore_errors=True)
            raise e

    async def _consume_loop(self):
        """
        æ¶ˆè´¹è€…å¾ªç¯ (Strict Serial Execution)ã€‚
        è¿™æ˜¯ä¿æŠ¤ M4 Pro æ˜¾å­˜çš„å…³é”®ã€‚
        """
        while self.is_running:
            # ä»é˜Ÿåˆ—è·å–ä»»åŠ¡
            job: TranscriptionJob = await self.queue.get()
            
            try:
                # === æ ¸å¿ƒæ¨ç†é€»è¾‘ ===
                # æ ¹æ® response_format å‚æ•°å†³å®šå¼•æ“è¿”å›æ ¼å¼
                format_param = job.params.get("response_format", "txt")
                
                # run_in_threadpool æ˜¯ä¸ºäº†æŠŠåŒæ­¥çš„ Engine ä»£ç æ”¾åˆ°çº¿ç¨‹æ± é‡Œè·‘
                # é˜²æ­¢é˜»å¡ asyncio çš„äº‹ä»¶å¾ªç¯
                result_data = await run_in_threadpool(
                    self.engine.transcribe_file,
                    file_path=job.temp_file_path,
                    language=job.params.get("language", "auto"),
                    use_itn=True,
                    format=format_param  # ä¼ é€’ format å‚æ•°ç»™ MLX å¼•æ“
                )

                # å¤„ç†è¿”å›å€¼ï¼ˆå¯èƒ½æ˜¯å­—ç¬¦ä¸²æˆ–å­—å…¸ï¼‰
                if isinstance(result_data, dict):
                    # MLX å¼•æ“è¿”å›äº† JSON æ ¼å¼ï¼ˆåŒ…å« segmentsï¼‰
                    raw_text = result_data.get("text", "")
                    # è°ƒç”¨é€‚é…å™¨æ¸…æ´—æ–‡æœ¬ï¼ˆä»…æ¸…ç†æ–‡æœ¬å†…å®¹ï¼Œä¸å½±å“ segmentsï¼‰
                    clean_tags = job.params.get("clean_tags", True)
                    cleaned_text = clean_sensevoice_tags(raw_text, clean_tags=clean_tags)
                    
                    # æ„é€ ç»“æœ
                    process_time = time.time() - job.received_at
                    result = {
                        "text": cleaned_text,
                        "duration": process_time,
                        "raw_text": raw_text,
                        "is_cleaned": clean_tags,
                        "segments": result_data.get("segments")  # é€ä¼  segments
                    }
                else:
                    # æ–‡æœ¬æ ¼å¼è¿”å›ï¼ˆFunASR æˆ– MLX txt æ ¼å¼ï¼‰
                    raw_text = result_data
                    # è°ƒç”¨é€‚é…å™¨æ¸…æ´—æ–‡æœ¬
                    clean_tags = job.params.get("clean_tags", True)
                    cleaned_text = clean_sensevoice_tags(raw_text, clean_tags=clean_tags)
                    
                    # æ„é€ ç»“æœ
                    process_time = time.time() - job.received_at
                    result = {
                        "text": cleaned_text,
                        "duration": process_time,
                        "raw_text": raw_text,
                        "is_cleaned": clean_tags
                    }
                
                # å”¤é†’ç­‰å¾…çš„ API è¯·æ±‚
                if not job.future.done():
                    job.future.set_result(result)

            except Exception as e:
                self.logger.exception(f"âŒ Job {job.uid} failed")
                if not job.future.done():
                    job.future.set_exception(e)
            
            finally:
                # === æ‰“æ‰«æˆ˜åœº ===
                # æ— è®ºæˆåŠŸå¤±è´¥ï¼Œå¿…é¡»åˆ é™¤ä¸´æ—¶ç›®å½•
                # è¿™ä¼šè¿å¸¦åˆ é™¤åŸå§‹æ–‡ä»¶ã€å½’ä¸€åŒ–æ–‡ä»¶ã€åˆ‡ç‰‡æ–‡ä»¶ç­‰æ‰€æœ‰ä¸­é—´äº§ç‰©
                if os.path.exists(job.temp_dir):
                    shutil.rmtree(job.temp_dir, ignore_errors=True)
                
                # æ ‡è®°é˜Ÿåˆ—ä»»åŠ¡å®Œæˆ
                self.queue.task_done()