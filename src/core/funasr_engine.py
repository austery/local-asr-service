import torch
import time
import gc
from funasr import AutoModel
from typing import Optional, Union, List, Dict

# æ¨èä½¿ç”¨çš„ Paraformer æ¨¡å‹ ID (æ”¯æŒæ—¶é—´æˆ³ï¼Œå¿…é¡»ç”¨äºè¯´è¯äººåˆ†ç¦»)
# SEACO-Paraformer æ˜¯ç›®å‰é˜¿é‡Œæœ€æˆç†Ÿçš„ä¸²è”æ¨¡å‹ï¼Œä¸­æ–‡è¯†åˆ« SOTA
DEFAULT_MODEL_ID = "iic/speech_seaco_paraformer_large_asr_nat-zh-cn-16k-common-vocab8404-pytorch"

# æ”¯æŒæ—¶é—´æˆ³ï¼ˆå’Œè¯´è¯äººåˆ†ç¦»ï¼‰çš„æ¨¡å‹ç™½åå•
# SenseVoice ç­‰å…¶ä»–æ¨¡å‹ä¸æ”¯æŒæ—¶é—´æˆ³ï¼Œä¸èƒ½åŠ è½½ spk_model
TIMESTAMP_CAPABLE_MODELS = {
    "iic/speech_seaco_paraformer_large_asr_nat-zh-cn-16k-common-vocab8404-pytorch",
    "iic/speech_paraformer-large-vad-punc_asr_nat-zh-cn-16k-common-vocab8404-pytorch",
}


class FunASREngine:
    """
    FunASR æ¨ç†å¼•æ“å°è£…ç±»ã€‚
    è´Ÿè´£æ¨¡å‹çš„ç”Ÿå‘½å‘¨æœŸç®¡ç†ï¼ˆåŠ è½½ã€æ¨ç†ã€èµ„æºé‡Šæ”¾ï¼‰ã€‚
    å®ç° ASREngine Protocolã€‚

    æ”¯æŒä¸¤ç§æ¨¡å¼ï¼š
    - Paraformer æ¨¡å‹ï¼šå®Œæ•´ç®¡é“ (VAD + ASR + Punc + CAM++ è¯´è¯äººåˆ†ç¦»)
    - SenseVoice ç­‰æ¨¡å‹ï¼šçº¯è½¬å½•æ¨¡å¼ (VAD + ASR + Puncï¼Œæ— è¯´è¯äººåˆ†ç¦»)
    """

    def __init__(self, model_id: str = DEFAULT_MODEL_ID, device: Optional[str] = None):
        self.model_id = model_id
        self.supports_timestamp = model_id in TIMESTAMP_CAPABLE_MODELS
        # è‡ªåŠ¨æ£€æµ‹ Apple Silicon (MPS) ç¯å¢ƒ
        if device is None:
            self.device = "mps" if torch.backends.mps.is_available() else "cpu"
        else:
            self.device = device

        self.model = None
        print(f"âš™ï¸ Engine initialized. Target device: {self.device}")
        if not self.supports_timestamp:
            print(f"â„¹ï¸  Model '{model_id}' does not support timestamps. Speaker diarization disabled.")

    def load(self):
        """
        åŠ è½½æ¨¡å‹ã€‚
        è¿™ä¸€æ­¥ä¼šè§¦å‘ FunASR çš„è‡ªåŠ¨æ£€æŸ¥æœºåˆ¶ï¼š
        1. æ£€æŸ¥æœ¬åœ°ç¼“å­˜ (~/.cache/modelscope)
        2. å¦‚æœä¸å­˜åœ¨ï¼Œè‡ªåŠ¨ä¸‹è½½
        3. åŠ è½½åˆ°å†…å­˜/æ˜¾å­˜
        """
        if self.model is not None:
            print("âš ï¸ Model already loaded. Skipping.")
            return

        print(f"ğŸš€ Loading model '{self.model_id}' on {self.device}...")
        print("   (If this is the first run, it will download the model automatically. Please wait.)")
        
        try:
            start_time = time.time()

            # æ ¹æ®æ¨¡å‹èƒ½åŠ›å†³å®šåŠ è½½çš„ç®¡é“ç»„ä»¶
            # Paraformer: VAD + ASR + Punc + CAM++ (å®Œæ•´è¯´è¯äººåˆ†ç¦»)
            # SenseVoice ç­‰: VAD + ASR + Punc (æ— è¯´è¯äººåˆ†ç¦»ï¼Œå› ä¸ºä¸æ”¯æŒæ—¶é—´æˆ³)
            model_kwargs = dict(
                model=self.model_id,
                vad_model="fsmn-vad",  # è¯­éŸ³æ´»åŠ¨æ£€æµ‹ï¼Œç”¨äºåˆ‡åˆ†é•¿éŸ³é¢‘
                vad_kwargs={"max_single_segment_time": 30000},  # 30ç§’åˆ‡ç‰‡ä¼˜åŒ–
                punc_model="ct-punc",  # æ ‡ç‚¹ç¬¦å·æ¨¡å‹
                device=self.device,
                disable_update=True,   # ç¦æ­¢æ¯æ¬¡éƒ½å» check updateï¼ŒåŠ å¿«å¯åŠ¨é€Ÿåº¦
                log_level="ERROR",     # å‡å°‘åˆ·å±æ—¥å¿—
            )
            if self.supports_timestamp:
                model_kwargs["spk_model"] = "cam++"  # å£°çº¹è¯†åˆ«æ¨¡å‹ï¼ˆè¯´è¯äººåˆ†ç¦»ï¼‰

            self.model = AutoModel(**model_kwargs)
            
            duration = time.time() - start_time
            print(f"âœ… Model loaded successfully in {duration:.2f}s")
            
        except Exception as e:
            print(f"âŒ Failed to load model: {e}")
            raise e

    def transcribe_file(
        self, 
        file_path: str, 
        language: str = "auto",
        output_format: str = "json",  # é€‰é¡¹: 'json', 'txt', 'srt'
        with_timestamp: bool = False,  # txt/srt ä¸­æ˜¯å¦åŒ…å«æ—¶é—´æˆ³
        **kwargs
    ) -> Union[Dict, str, List[Dict]]:
        """
        æ‰§è¡Œæ¨ç†ï¼Œæ”¯æŒå¤šç§è¾“å‡ºæ ¼å¼ã€‚
        
        Args:
            file_path: éŸ³é¢‘æ–‡ä»¶è·¯å¾„
            language: è¯­è¨€ä»£ç  (auto, zh, en, yue, ja, ko)
            output_format: è¾“å‡ºæ ¼å¼
                - 'json': è¿”å›å®Œæ•´ç»“æ„åŒ–æ•°æ® (æ¨èå­˜å‚¨ï¼ŒåŒ…å«æ—¶é—´æˆ³å’Œè¯´è¯äºº)
                - 'txt': è¿”å›äººç±»æ˜“è¯»æ–‡æœ¬ (é€‚åˆ RAG/LLM)
                - 'srt': è¿”å› SRT å­—å¹•æ ¼å¼
            with_timestamp: å¦‚æœæ˜¯ txt æ ¼å¼ï¼Œæ˜¯å¦åœ¨è¡Œé¦–ä¿ç•™ [00:12] æ—¶é—´æ ‡è®°
            
        Returns:
            æ ¹æ® output_format è¿”å›ä¸åŒæ ¼å¼:
            - json: {"text": str, "segments": List[Dict]}
            - txt: str
            - srt: str
            
        æ³¨æ„ï¼šè¿™æ˜¯åŒæ­¥é˜»å¡æ–¹æ³•ï¼Œå¿…é¡»åœ¨ Service å±‚é€šè¿‡çº¿ç¨‹æ± è°ƒç”¨ã€‚
        """
        if not self.model:
            raise RuntimeError("Model not loaded! Call engine.load() first.")

        # ä» kwargs æå– FunASR ç‰¹å®šå‚æ•°
        use_itn = kwargs.get("use_itn", True)

        # SenseVoice ä¸æ”¯æŒæ—¶é—´æˆ³/è¯´è¯äººåˆ†ç¦»ï¼Œå¼ºåˆ¶é™çº§ä¸º txt
        if not self.supports_timestamp and output_format == "srt":
            output_format = "txt"

        # è°ƒç”¨ FunASR æ¨ç†
        res = self.model.generate(
            input=file_path,
            cache={},
            use_itn=use_itn,       # é€†æ–‡æœ¬æ ‡å‡†åŒ– (ä¸€ç™¾ -> 100)
            batch_size_s=60,       # æ‰¹å¤„ç†å¤§å° (60ç§’éŸ³é¢‘åˆ‡ç‰‡)
            merge_vad=True,        # è‡ªåŠ¨åˆå¹¶çŸ­å¥
            merge_length_s=15
        )

        # è§£æç»“æœ
        result_data = res[0] if res else {}
        text = result_data.get("text", "")

        # SenseVoice è¾“å‡ºåŒ…å«ç‰¹æ®Šæ ‡ç­¾ (<|zh|><|NEUTRAL|> ç­‰)ï¼Œéœ€è¦æ¸…æ´—
        if not self.supports_timestamp:
            from src.adapters.text import clean_sensevoice_tags
            text = clean_sensevoice_tags(text)

        sentence_info = result_data.get("sentence_info", [])

        # === å†…å­˜ä¼˜åŒ–ï¼šæ‰“æ‰«æˆ˜åœº ===
        if self.device == "mps":
            torch.mps.empty_cache()
        elif self.device == "cuda":
            torch.cuda.empty_cache()

        # å…œåº•ï¼šå¦‚æœæ¨¡å‹æ²¡è¿”å›åˆ†å¥ä¿¡æ¯ï¼Œç›´æ¥è¿”å›å…¨æ–‡
        if not sentence_info:
            if output_format == "json":
                return {"text": text, "segments": None}
            return text

        # æ ¹æ® output_format æ ¼å¼åŒ–è¾“å‡º
        if output_format == "json":
            return self._format_as_json(text, sentence_info)
        elif output_format == "txt":
            return self._format_as_txt(sentence_info, with_timestamp)
        elif output_format == "srt":
            return self._format_as_srt(sentence_info)
        
        # é»˜è®¤è¿”å› JSON
        return self._format_as_json(text, sentence_info)

    def _format_as_json(self, text: str, sentence_info: List[Dict]) -> Dict:
        """
        è¿”å›å®Œæ•´çš„ç»“æ„åŒ–æ•°æ®ã€‚
        è¿™æ˜¯ä½ çš„"æ•°å­—èµ„äº§"ï¼ŒåŒ…å«æ‰€æœ‰åŸå§‹ä¿¡æ¯ä»¥ä¾¿åç»­å¤„ç†ã€‚
        """
        segments = [
            {
                "speaker": f"Speaker {info.get('spk', 0)}",
                "text": info.get("text", ""),
                "start": info.get("start", 0),  # æ¯«ç§’
                "end": info.get("end", 0)       # æ¯«ç§’
            }
            for info in sentence_info
        ]
        return {"text": text, "segments": segments}

    def _format_as_txt(self, sentence_info: List[Dict], with_timestamp: bool) -> str:
        """
        ç”Ÿæˆäººç±»æ˜“è¯»çš„è®¿è°ˆæ–‡æœ¬ã€‚
        é€‚åˆç”¨äº RAG çŸ¥è¯†åº“æˆ– LLM å¤„ç†ã€‚
        
        æ ¼å¼æ ·ä¾‹:
        - çº¯å‡€æ¨¡å¼: [Speaker 0]: å¤§å®¶å¥½...
        - å¸¦æ—¶é—´æˆ³: [02:15] [Speaker 0]: å¤§å®¶å¥½...
        """
        lines = []
        
        for info in sentence_info:
            spk = info.get("spk")
            text = info.get("text", "")
            start_ms = info.get("start", 0)
            
            # æ ¼å¼åŒ–è¯´è¯äººæ ‡ç­¾
            spk_tag = f"[Speaker {spk}]" if spk is not None else "[Unknown]"
            
            # æ ¼å¼åŒ–æ—¶é—´æˆ³ (ä»…å½“ç”¨æˆ·éœ€è¦æ—¶)
            time_tag = ""
            if with_timestamp and start_ms is not None:
                # æ¯«ç§’ -> MM:SS
                seconds = int(start_ms / 1000)
                m, s = divmod(seconds, 60)
                time_tag = f"[{m:02d}:{s:02d}] "

            # ç»„åˆä¸€è¡Œ
            line = f"{time_tag}{spk_tag}: {text}"
            lines.append(line)
            
        return "\n".join(lines)

    def _format_as_srt(self, sentence_info: List[Dict]) -> str:
        """
        ç”Ÿæˆæ ‡å‡† SRT å­—å¹•æ ¼å¼ã€‚
        
        æ ¼å¼:
        1
        00:00:05,000 --> 00:00:20,000
        [Speaker 0]: so what is some of the questionsï¼Ÿ
        """
        lines = []
        
        for idx, info in enumerate(sentence_info, start=1):
            spk = info.get("spk", 0)
            text = info.get("text", "")
            start_ms = info.get("start", 0)
            end_ms = info.get("end", 0)
            
            # æ¯«ç§’è½¬ SRT æ—¶é—´æ ¼å¼ (HH:MM:SS,mmm)
            start_srt = self._ms_to_srt_time(start_ms)
            end_srt = self._ms_to_srt_time(end_ms)
            
            # SRT æ ¼å¼
            lines.append(str(idx))
            lines.append(f"{start_srt} --> {end_srt}")
            lines.append(f"[Speaker {spk}]: {text}")
            lines.append("")  # ç©ºè¡Œåˆ†éš”
            
        return "\n".join(lines)

    def _ms_to_srt_time(self, ms: int) -> str:
        """å°†æ¯«ç§’è½¬æ¢ä¸º SRT æ—¶é—´æ ¼å¼ (HH:MM:SS,mmm)"""
        if ms < 0:
            ms = 0
        hours = ms // 3600000
        minutes = (ms % 3600000) // 60000
        seconds = (ms % 60000) // 1000
        milliseconds = ms % 1000
        return f"{hours:02d}:{minutes:02d}:{seconds:02d},{milliseconds:03d}"

    def release(self):
        """
        é‡Šæ”¾æ˜¾å­˜èµ„æºã€‚
        ç”¨äºçƒ­æ›´æ–°æ¨¡å‹æˆ–æœåŠ¡å…³é—­æ—¶æ¸…ç†èµ„æºã€‚
        """
        if self.model:
            print(f"â™»ï¸ Releasing model '{self.model_id}'...")
            del self.model
            self.model = None
            
            if self.device == "mps":
                torch.mps.empty_cache()
            elif self.device == "cuda":
                torch.cuda.empty_cache()
            
            gc.collect()
            print("âœ… Model released and memory cleared.")