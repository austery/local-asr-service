"""
MLX Audio æ¨ç†å¼•æ“å°è£…ç±»ã€‚
æ”¯æŒ Qwen3-ASRã€Whisperã€Parakeet ç­‰ mlx-audio å…¼å®¹æ¨¡å‹ã€‚
æ”¯æŒè‡ªåŠ¨éŸ³é¢‘åˆ‡ç‰‡ï¼ˆé•¿éŸ³é¢‘è¶…è¿‡é™åˆ¶æ—¶ï¼‰ã€‚
æ”¯æŒè¯´è¯äººåˆ†ç¦»ï¼ˆæŸäº›æ¨¡å‹ç‰¹æ€§ï¼‰ã€‚
"""
import time
import gc
from pathlib import Path
from typing import Optional, Dict, Any, List, Union

from mlx_audio.stt.utils import load_model
from mlx_audio.stt.generate import generate_transcription

from src.adapters.audio_chunking import AudioChunkingService


class MlxAudioEngine:
    """
    MLX Audio é€šç”¨æ¨ç†å¼•æ“ã€‚
    æ”¯æŒæ‰€æœ‰ mlx-audio å…¼å®¹çš„ STT æ¨¡å‹ã€‚
    å®ç° ASREngine Protocolã€‚
    """

    def __init__(self, model_id: str = "mlx-community/Qwen3-ASR-1.7B-4bit"):
        self.model_id = model_id
        self.model = None
        self.chunking_service = AudioChunkingService()
        print(f"âš™ï¸ MLX Engine initialized. Model: {self.model_id}")

    def load(self) -> None:
        """
        åŠ è½½æ¨¡å‹ã€‚
        mlx-audio ä¼šè‡ªåŠ¨å¤„ç†ï¼š
        1. æ£€æŸ¥æœ¬åœ°ç¼“å­˜ (~/.cache/huggingface)
        2. å¦‚æœä¸å­˜åœ¨ï¼Œè‡ªåŠ¨ä¸‹è½½
        3. åŠ è½½åˆ° MLX ç»Ÿä¸€å†…å­˜
        """
        if self.model is not None:
            print("âš ï¸ Model already loaded. Skipping.")
            return

        print(f"ğŸš€ Loading MLX model '{self.model_id}'...")
        print("   (If this is the first run, it will download the model automatically. Please wait.)")

        try:
            start_time = time.time()
            self.model = load_model(self.model_id)
            duration = time.time() - start_time
            print(f"âœ… MLX Model loaded successfully in {duration:.2f}s")
        except Exception as e:
            print(f"âŒ Failed to load MLX model: {e}")
            raise e

    def transcribe_file(
        self, 
        file_path: str, 
        language: str = "auto", 
        **kwargs
    ) -> Union[str, Dict[str, Any]]:
        """
        æ‰§è¡Œæ¨ç†ï¼Œè¿”å›è½¬å½•ç»“æœã€‚
        è‡ªåŠ¨å¤„ç†é•¿éŸ³é¢‘åˆ‡ç‰‡ã€‚
        æ”¯æŒå¤šç§è¾“å‡ºæ ¼å¼ï¼ˆtxt, json, srt, vttï¼‰ã€‚
        
        Args:
            file_path: éŸ³é¢‘æ–‡ä»¶è·¯å¾„
            language: è¯­è¨€ä»£ç  (å½“å‰ mlx-audio éƒ¨åˆ†æ¨¡å‹æ”¯æŒ)
            **kwargs: å…¶ä»–å‚æ•°
                - verbose: bool - è¯¦ç»†è¾“å‡º
                - format: str - è¾“å‡ºæ ¼å¼ (txt, json, srt, vtt)
                - response_format: str - OpenAI å…¼å®¹çš„å“åº”æ ¼å¼å‚æ•°
            
        Returns:
            txt æ ¼å¼: è½¬å½•æ–‡æœ¬å­—ç¬¦ä¸²
            json æ ¼å¼: åŒ…å« text å’Œ segments çš„å­—å…¸ï¼ˆè¯´è¯äººä¿¡æ¯ï¼‰
        """
        if not self.model:
            raise RuntimeError("Model not loaded! Call engine.load() first.")

        verbose = kwargs.get("verbose", False)
        # æ”¯æŒä¸¤ç§å‚æ•°åï¼šformat (mlx-audio) å’Œ response_format (OpenAI)
        output_format = kwargs.get("format") or kwargs.get("response_format", "txt")
        
        # æ ‡å‡†åŒ–æ ¼å¼åç§°
        if output_format in ["json", "verbose_json"]:
            output_format = "json"
        elif output_format not in ["txt", "srt", "vtt"]:
            output_format = "txt"  # é»˜è®¤æ–‡æœ¬æ ¼å¼
        
        try:
            # æ­¥éª¤1: æ£€æŸ¥éŸ³é¢‘æ˜¯å¦éœ€è¦åˆ‡ç‰‡
            chunks = self.chunking_service.process_audio(file_path)
            
            # æ­¥éª¤2: è½¬å½•æ‰€æœ‰åˆ‡ç‰‡
            results = []
            for i, chunk_path in enumerate(chunks):
                print(f"ğŸ™ï¸ Transcribing chunk {i + 1}/{len(chunks)} (format: {output_format})...")
                try:
                    result = generate_transcription(
                        model=self.model,
                        audio=chunk_path,
                        format=output_format,
                        verbose=verbose
                    )
                    results.append(result)
                finally:
                    # æ¸…ç†ä¸´æ—¶åˆ‡ç‰‡æ–‡ä»¶
                    if chunk_path != chunks[0] or len(chunks) > 1:
                        if ".chunk_" in chunk_path or len(chunks) > 1:
                            Path(chunk_path).unlink(missing_ok=True)
            
            # æ­¥éª¤3: æ ¹æ®æ ¼å¼åˆå¹¶ç»“æœ
            if output_format == "json":
                final_result = self._merge_json_results(results)
            else:
                # txt, srt, vtt æ ¼å¼
                texts = []
                for result in results:
                    text = result.text.strip() if hasattr(result, 'text') else str(result).strip()
                    texts.append(text)
                final_result = " ".join(texts)
            
            if len(chunks) > 1:
                print(f"âœ… Successfully merged {len(chunks)} chunks")
            
            return final_result
            
        except Exception as e:
            print(f"âŒ MLX transcription failed: {e}")
            raise e
    
    def _merge_json_results(self, results: List[Any]) -> Dict[str, Any]:
        """
        åˆå¹¶å¤šä¸ª JSON æ ¼å¼çš„è½¬å½•ç»“æœã€‚
        
        Args:
            results: mlx-audio è¿”å›çš„ç»“æœå¯¹è±¡åˆ—è¡¨
            
        Returns:
            åˆå¹¶åçš„å­—å…¸ï¼ŒåŒ…å« text å’Œ segments
        """
        if not results:
            return {"text": "", "segments": []}
        
        # å¦‚æœåªæœ‰ä¸€ä¸ªç»“æœï¼Œç›´æ¥è½¬æ¢
        if len(results) == 1:
            return self._result_to_dict(results[0])
        
        # åˆå¹¶å¤šä¸ªç»“æœ
        all_text = []
        all_segments = []
        time_offset = 0.0
        
        for i, result in enumerate(results):
            result_dict = self._result_to_dict(result)
            
            # ç´¯åŠ æ–‡æœ¬
            all_text.append(result_dict.get("text", ""))
            
            # è°ƒæ•´æ—¶é—´æˆ³å¹¶åˆå¹¶ segments
            segments = result_dict.get("segments", [])
            for segment in segments:
                adjusted_segment = segment.copy()
                if "start" in adjusted_segment:
                    adjusted_segment["start"] += time_offset
                if "end" in adjusted_segment:
                    adjusted_segment["end"] += time_offset
                all_segments.append(adjusted_segment)
            
            # æ›´æ–°æ—¶é—´åç§»ï¼ˆä½¿ç”¨æœ€åä¸€ä¸ª segment çš„ç»“æŸæ—¶é—´ï¼‰
            if segments and "end" in segments[-1]:
                time_offset = segments[-1]["end"] + time_offset
        
        return {
            "text": " ".join(all_text),
            "segments": all_segments
        }
    
    def _result_to_dict(self, result: Any) -> Dict[str, Any]:
        """
        å°† mlx-audio ç»“æœå¯¹è±¡è½¬æ¢ä¸ºå­—å…¸ã€‚
        
        Args:
            result: mlx-audio è¿”å›çš„ç»“æœå¯¹è±¡
            
        Returns:
            åŒ…å« text å’Œ segments çš„å­—å…¸
        """
        result_dict = {"text": "", "segments": []}
        
        # æå–æ–‡æœ¬
        if hasattr(result, 'text'):
            result_dict["text"] = result.text.strip()
        elif isinstance(result, dict):
            result_dict["text"] = result.get("text", "")
        
        # æå– segmentsï¼ˆè¯´è¯äººä¿¡æ¯ï¼‰
        if hasattr(result, 'segments'):
            segments = result.segments
            if isinstance(segments, list):
                result_dict["segments"] = [
                    self._normalize_segment(seg) for seg in segments
                ]
        elif isinstance(result, dict) and "segments" in result:
            result_dict["segments"] = [
                self._normalize_segment(seg) for seg in result["segments"]
            ]
        
        return result_dict
    
    def _normalize_segment(self, segment: Any) -> Dict[str, Any]:
        """
        æ ‡å‡†åŒ– segment æ ¼å¼ã€‚
        
        Args:
            segment: åŸå§‹ segment å¯¹è±¡æˆ–å­—å…¸
            
        Returns:
            æ ‡å‡†åŒ–çš„ segment å­—å…¸
        """
        normalized = {}
        
        # å¤„ç†å­—å…¸æ ¼å¼
        if isinstance(segment, dict):
            normalized = segment.copy()
        # å¤„ç†å¯¹è±¡æ ¼å¼
        else:
            for attr in ["speaker", "start", "end", "text"]:
                if hasattr(segment, attr):
                    normalized[attr] = getattr(segment, attr)
        
        return normalized

    def release(self) -> None:
        """
        é‡Šæ”¾èµ„æºã€‚
        MLX ä½¿ç”¨ç»Ÿä¸€å†…å­˜ï¼Œä¸»è¦é€šè¿‡ Python GC æ¸…ç†ã€‚
        """
        if self.model:
            print(f"â™»ï¸ Releasing MLX model '{self.model_id}'...")
            del self.model
            self.model = None
            gc.collect()
            print("âœ… MLX Model released.")
