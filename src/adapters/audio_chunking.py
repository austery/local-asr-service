"""
éŸ³é¢‘åˆ‡ç‰‡æœåŠ¡ (Audio Chunking Service)

ç”¨äºå¤„ç†è¶…é•¿éŸ³é¢‘ï¼Œæä¾›æ™ºèƒ½åˆ‡ç‰‡åŠŸèƒ½ã€‚
æ ¸å¿ƒç­–ç•¥ï¼š
1. å½’ä¸€åŒ–ï¼šè½¬æ¢ä¸º mono, 16kHzï¼ˆWhisper æ¨¡å‹æœ€ä¼˜æ ¼å¼ï¼‰
2. æ™ºèƒ½åˆ‡ç‰‡ï¼šå¦‚æœè¶…è¿‡é™åˆ¶ï¼Œåœ¨é™éŸ³ç‚¹åˆ‡åˆ†ï¼ˆé¿å…æ–­è¯ï¼‰

Reference: puresubs/AudioChunkingService.ts
"""

import os
import re
import subprocess
from pathlib import Path
from typing import List, Optional, NamedTuple
from dataclasses import dataclass

from src.config import (
    MAX_AUDIO_DURATION_MINUTES,
    SILENCE_THRESHOLD_SEC,
    SILENCE_NOISE_DB,
    AUDIO_SAMPLE_RATE,
    AUDIO_BITRATE,
    CHUNK_OVERLAP_SECONDS,
)


class AudioNormalizationResult(NamedTuple):
    """éŸ³é¢‘å½’ä¸€åŒ–ç»“æœ"""
    normalized_path: str
    file_size_bytes: int
    duration_seconds: float


@dataclass
class SilenceInterval:
    """é™éŸ³åŒºé—´"""
    start: float  # å¼€å§‹æ—¶é—´(ç§’)
    end: float    # ç»“æŸæ—¶é—´(ç§’)
    duration: float  # æŒç»­æ—¶é—´(ç§’)


class AudioChunkingService:
    """
    éŸ³é¢‘åˆ‡ç‰‡æœåŠ¡
    
    æ”¯æŒä¸¤ç§åˆ‡ç‰‡ç­–ç•¥ï¼š
    - ç­–ç•¥A (ä¼˜å…ˆ)ï¼šåŸºäºé™éŸ³æ£€æµ‹çš„æ™ºèƒ½åˆ‡ç‰‡
    - ç­–ç•¥B (fallback)ï¼šå›ºå®šæ—¶é•¿ + é‡å åˆ‡ç‰‡
    """
    
    def __init__(
        self,
        max_duration_minutes: int = MAX_AUDIO_DURATION_MINUTES,
        silence_threshold_sec: float = SILENCE_THRESHOLD_SEC,
        silence_noise_db: str = SILENCE_NOISE_DB,
        sample_rate: int = AUDIO_SAMPLE_RATE,
        bitrate: str = AUDIO_BITRATE,
        overlap_seconds: int = CHUNK_OVERLAP_SECONDS,
    ):
        self.max_duration_seconds = max_duration_minutes * 60
        self.silence_threshold_sec = silence_threshold_sec
        self.silence_noise_db = silence_noise_db
        self.sample_rate = sample_rate
        self.bitrate = bitrate
        self.overlap_seconds = overlap_seconds
        
        # æ£€æŸ¥ ffmpeg å’Œ ffprobe æ˜¯å¦å¯ç”¨
        self._check_ffmpeg_availability()
        
        print(f"ğŸ›ï¸  AudioChunkingService initialized:")
        print(f"   - Max duration: {max_duration_minutes} min")
        print(f"   - Silence threshold: {silence_threshold_sec}s @ {silence_noise_db}")
        print(f"   - Sample rate: {sample_rate}Hz, Bitrate: {bitrate}")
        print(f"   - Overlap duration: {overlap_seconds}s (fallback)")
    
    def _check_ffmpeg_availability(self):
        """æ£€æŸ¥ ffmpeg å’Œ ffprobe æ˜¯å¦å¯ç”¨"""
        try:
            subprocess.run(
                ["ffmpeg", "-version"],
                stdout=subprocess.DEVNULL,
                stderr=subprocess.DEVNULL,
                check=True,
            )
            subprocess.run(
                ["ffprobe", "-version"],
                stdout=subprocess.DEVNULL,
                stderr=subprocess.DEVNULL,
                check=True,
            )
        except (subprocess.CalledProcessError, FileNotFoundError) as e:
            raise RuntimeError(
                "âŒ ffmpeg and ffprobe are required for audio chunking. "
                "Install with: brew install ffmpeg"
            ) from e
    
    async def process_audio(self, input_path: str) -> List[str]:
        """
        å¤„ç†éŸ³é¢‘ï¼šå½’ä¸€åŒ–å¹¶åœ¨å¿…è¦æ—¶åˆ‡ç‰‡
        
        Args:
            input_path: åŸå§‹éŸ³é¢‘æ–‡ä»¶è·¯å¾„
            
        Returns:
            éŸ³é¢‘æ–‡ä»¶è·¯å¾„åˆ—è¡¨ï¼ˆå¦‚æœä¸éœ€è¦åˆ‡ç‰‡åˆ™åªæœ‰ä¸€ä¸ªè·¯å¾„ï¼‰
        """
        print(f"ğŸµ Processing audio: {Path(input_path).name}")
        
        # Step 1: å½’ä¸€åŒ–éŸ³é¢‘ï¼ˆmono, 16kHzï¼‰
        normalized = await self._normalize_audio(input_path)
        print(f"   âœ“ Normalized: {normalized.file_size_bytes / 1024 / 1024:.2f}MB, "
              f"{normalized.duration_seconds:.1f}s")
        
        # Step 2: æ£€æŸ¥æ˜¯å¦éœ€è¦åˆ‡ç‰‡
        if normalized.duration_seconds <= self.max_duration_seconds:
            print(f"   âœ“ Duration OK, no chunking needed")
            return [normalized.normalized_path]
        
        # Step 3: éœ€è¦åˆ‡ç‰‡
        print(f"   âš ï¸  Audio duration ({normalized.duration_seconds / 60:.1f} min) "
              f"exceeds limit ({self.max_duration_seconds / 60:.1f} min)")
        
        # ç­–ç•¥A: å°è¯•é™éŸ³åˆ‡ç‰‡ï¼ˆè‡ªé€‚åº”é˜ˆå€¼ï¼‰
        thresholds = ["-40dB", "-35dB", "-30dB", "-25dB"]
        for threshold in thresholds:
            print(f"   ğŸ” Trying silence-based splitting at {threshold}...")
            try:
                chunks = await self._try_silence_split(
                    normalized.normalized_path,
                    normalized.duration_seconds,
                    threshold,
                )
                if chunks:
                    print(f"   âœ… Success with silence splitting at {threshold}")
                    return chunks
            except Exception as e:
                print(f"   âš ï¸  Failed at {threshold}: {e}")
                continue
        
        # ç­–ç•¥B: Fallback åˆ°é‡å åˆ‡ç‰‡
        print(f"   âš ï¸  All silence detection attempts failed. Using overlap splitting.")
        return await self._split_with_overlap(
            normalized.normalized_path,
            normalized.duration_seconds,
        )
    
    async def _normalize_audio(self, input_path: str) -> AudioNormalizationResult:
        """
        å½’ä¸€åŒ–éŸ³é¢‘åˆ°æœ€ä¼˜æ ¼å¼
        - å•å£°é“ï¼ˆè¯­éŸ³ä¸éœ€è¦ç«‹ä½“å£°ï¼‰
        - 16kHz é‡‡æ ·ç‡ï¼ˆWhisper æ ‡å‡†ï¼‰
        - é€‚åº¦å‹ç¼©ç ç‡
        """
        input_p = Path(input_path)
        output_path = str(input_p.with_suffix(".normalized.mp3"))
        
        print(f"   ğŸ”§ Normalizing audio...")
        
        cmd = [
            "ffmpeg",
            "-i", input_path,
            "-ac", "1",  # Mono
            "-ar", str(self.sample_rate),  # 16kHz
            "-b:a", self.bitrate,  # 64k
            "-y",  # Overwrite
            output_path,
        ]
        
        try:
            subprocess.run(
                cmd,
                stdout=subprocess.DEVNULL,
                stderr=subprocess.PIPE,
                check=True,
                text=True,
            )
            
            file_size = Path(output_path).stat().st_size
            duration = await self._get_audio_duration(output_path)
            
            return AudioNormalizationResult(
                normalized_path=output_path,
                file_size_bytes=file_size,
                duration_seconds=duration,
            )
        except subprocess.CalledProcessError as e:
            raise RuntimeError(f"Audio normalization failed: {e.stderr}") from e
    
    async def _get_audio_duration(self, audio_path: str) -> float:
        """ä½¿ç”¨ ffprobe è·å–éŸ³é¢‘æ—¶é•¿"""
        cmd = [
            "ffprobe",
            "-v", "error",
            "-show_entries", "format=duration",
            "-of", "default=noprint_wrappers=1:nokey=1",
            audio_path,
        ]
        
        try:
            result = subprocess.run(
                cmd,
                stdout=subprocess.PIPE,
                stderr=subprocess.PIPE,
                check=True,
                text=True,
            )
            return float(result.stdout.strip())
        except (subprocess.CalledProcessError, ValueError) as e:
            raise RuntimeError(f"Failed to get audio duration: {e}") from e
    
    async def _detect_silence(
        self,
        audio_path: str,
        threshold: str,
    ) -> List[SilenceInterval]:
        """
        ä½¿ç”¨ ffmpeg silencedetect æ£€æµ‹é™éŸ³åŒºé—´
        
        Args:
            audio_path: éŸ³é¢‘æ–‡ä»¶è·¯å¾„
            threshold: å™ªéŸ³é˜ˆå€¼ï¼ˆå¦‚ "-30dB"ï¼‰
            
        Returns:
            é™éŸ³åŒºé—´åˆ—è¡¨
        """
        cmd = [
            "ffmpeg",
            "-i", audio_path,
            "-af", f"silencedetect=noise={threshold}:d={self.silence_threshold_sec}",
            "-f", "null",
            "-",
        ]
        
        try:
            result = subprocess.run(
                cmd,
                stdout=subprocess.PIPE,
                stderr=subprocess.PIPE,
                text=True,
            )
            output = result.stdout + result.stderr
            
            # è§£æ silencedetect è¾“å‡º
            # Format: [silencedetect @ ...] silence_start: 12.345
            #         [silencedetect @ ...] silence_end: 13.456 | silence_duration: 1.111
            silences: List[SilenceInterval] = []
            current_start: Optional[float] = None
            
            for line in output.split("\n"):
                start_match = re.search(r"silence_start:\s+([\d.]+)", line)
                end_match = re.search(r"silence_end:\s+([\d.]+)", line)
                
                if start_match:
                    current_start = float(start_match.group(1))
                elif end_match and current_start is not None:
                    end = float(end_match.group(1))
                    silences.append(SilenceInterval(
                        start=current_start,
                        end=end,
                        duration=end - current_start,
                    ))
                    current_start = None
            
            return silences
        except Exception as e:
            print(f"   âŒ Silence detection failed: {e}")
            return []
    
    async def _try_silence_split(
        self,
        audio_path: str,
        duration_seconds: float,
        threshold: str,
    ) -> List[str]:
        """
        å°è¯•åœ¨é™éŸ³ç‚¹åˆ‡åˆ†éŸ³é¢‘
        
        å¦‚æœåˆ‡åˆ†ç‚¹ä¸è¶³æˆ–åˆ‡ç‰‡ä»è¿‡å¤§ï¼Œè¿”å›ç©ºåˆ—è¡¨
        """
        # 1. æ£€æµ‹é™éŸ³
        silences = await self._detect_silence(audio_path, threshold)
        if not silences:
            return []
        
        # 2. è®¡ç®—ç†æƒ³åˆ‡åˆ†ç‚¹æ•°é‡
        num_chunks = int((duration_seconds / self.max_duration_seconds) + 0.5)
        if num_chunks < 2:
            return []
        
        # 3. è®¡ç®—ç†æƒ³åˆ‡åˆ†æ—¶é—´ç‚¹
        ideal_split_times = [
            (duration_seconds / num_chunks) * i
            for i in range(1, num_chunks)
        ]
        
        # 4. å°†ç†æƒ³æ—¶é—´ç‚¹å¯¹é½åˆ°æœ€è¿‘çš„é™éŸ³ä¸­ç‚¹
        actual_split_times = [
            self._find_nearest_silence_midpoint(silences, ideal_time)
            for ideal_time in ideal_split_times
        ]
        
        # 5. å»é‡å¹¶éªŒè¯
        unique_splits = sorted(set(actual_split_times))
        unique_splits = [
            t for t in unique_splits
            if 1.0 < t < duration_seconds - 1.0
        ]
        
        if not unique_splits and num_chunks > 1:
            return []
        
        # 6. æ‰§è¡Œåˆ‡åˆ†
        chunks = await self._split_audio_at_points(audio_path, unique_splits)
        
        # 7. éªŒè¯æ‰€æœ‰åˆ‡ç‰‡éƒ½åœ¨æ—¶é•¿é™åˆ¶å†…
        all_valid = all(
            await self._get_audio_duration(chunk) <= self.max_duration_seconds
            for chunk in chunks
        )
        
        if not all_valid:
            print(f"      âŒ Some chunks still exceed limit. Discarding...")
            for chunk in chunks:
                Path(chunk).unlink(missing_ok=True)
            return []
        
        return chunks
    
    def _find_nearest_silence_midpoint(
        self,
        silences: List[SilenceInterval],
        target_time: float,
    ) -> float:
        """æ‰¾åˆ°æœ€æ¥è¿‘ç›®æ ‡æ—¶é—´çš„é™éŸ³åŒºé—´ä¸­ç‚¹"""
        if not silences:
            return target_time
        
        def midpoint(s: SilenceInterval) -> float:
            return (s.start + s.end) / 2
        
        nearest = min(silences, key=lambda s: abs(midpoint(s) - target_time))
        return midpoint(nearest)
    
    async def _split_audio_at_points(
        self,
        audio_path: str,
        split_times: List[float],
    ) -> List[str]:
        """åœ¨æŒ‡å®šæ—¶é—´ç‚¹åˆ‡åˆ†éŸ³é¢‘"""
        audio_p = Path(audio_path)
        duration = await self._get_audio_duration(audio_path)
        
        # æ·»åŠ èµ·ç‚¹å’Œç»ˆç‚¹
        all_points = [0.0] + split_times + [duration]
        
        chunk_paths: List[str] = []
        
        for i in range(len(all_points) - 1):
            start = all_points[i]
            end = all_points[i + 1]
            chunk_path = str(audio_p.with_suffix(f".chunk_{i}{audio_p.suffix}"))
            
            print(f"   âœ‚ï¸  Creating chunk {i}: {start:.1f}s - {end:.1f}s")
            
            cmd = [
                "ffmpeg",
                "-i", audio_path,
                "-ss", str(start),
                "-to", str(end),
                "-c", "copy",  # ä¸é‡æ–°ç¼–ç ï¼ˆå¿«é€Ÿï¼‰
                "-y",
                chunk_path,
            ]
            
            try:
                subprocess.run(
                    cmd,
                    stdout=subprocess.DEVNULL,
                    stderr=subprocess.PIPE,
                    check=True,
                    text=True,
                )
                chunk_paths.append(chunk_path)
                
                chunk_size = Path(chunk_path).stat().st_size
                print(f"      âœ“ Chunk {i}: {chunk_size / 1024 / 1024:.2f}MB")
            except subprocess.CalledProcessError as e:
                raise RuntimeError(f"Failed to create chunk {i}: {e.stderr}") from e
        
        return chunk_paths
    
    async def _split_with_overlap(
        self,
        audio_path: str,
        duration_seconds: float,
    ) -> List[str]:
        """
        ä½¿ç”¨å›ºå®šæ—¶é•¿ + é‡å ç­–ç•¥åˆ‡åˆ†éŸ³é¢‘
        
        å½“é™éŸ³æ£€æµ‹å¤±è´¥æ—¶ä½¿ç”¨æ­¤ç­–ç•¥
        """
        # è®¡ç®—åˆ‡ç‰‡æ•°é‡ï¼ˆç•™ 10% å®‰å…¨è£•åº¦ï¼‰
        num_chunks = int((duration_seconds / self.max_duration_seconds) + 1)
        chunk_duration = duration_seconds / num_chunks
        
        print(f"   âœ‚ï¸  Overlap splitting: {num_chunks} chunks, "
              f"base duration ~{chunk_duration:.1f}s, "
              f"overlap {self.overlap_seconds}s")
        
        audio_p = Path(audio_path)
        chunk_paths: List[str] = []
        
        start_time = 0.0
        chunk_index = 0
        
        while start_time < duration_seconds:
            end_time = min(start_time + chunk_duration, duration_seconds)
            chunk_path = str(audio_p.with_suffix(f".chunk_ov_{chunk_index}{audio_p.suffix}"))
            
            print(f"      Generating chunk {chunk_index}: {start_time:.1f}s - {end_time:.1f}s")
            
            cmd = [
                "ffmpeg",
                "-i", audio_path,
                "-ss", str(start_time),
                "-to", str(end_time),
                "-c", "copy",
                "-y",
                chunk_path,
            ]
            
            try:
                subprocess.run(
                    cmd,
                    stdout=subprocess.DEVNULL,
                    stderr=subprocess.PIPE,
                    check=True,
                    text=True,
                )
                chunk_paths.append(chunk_path)
                
                chunk_size = Path(chunk_path).stat().st_size
                print(f"      âœ“ Chunk {chunk_index}: {chunk_size / 1024 / 1024:.2f}MB")
            except subprocess.CalledProcessError as e:
                raise RuntimeError(
                    f"Failed to create overlap chunk {chunk_index}: {e.stderr}"
                ) from e
            
            if end_time >= duration_seconds:
                break
            
            # å‘å‰æ¨è¿›ï¼Œä½†å›é€€é‡å æ—¶é•¿
            start_time = end_time - self.overlap_seconds
            chunk_index += 1
        
        return chunk_paths
